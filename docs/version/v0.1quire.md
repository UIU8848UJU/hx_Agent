  
  
- [AI 文档整理与知识库 Agent v0.1 需求文档（SQLite First）](#ai-文档整理与知识库-agent-v01-需求文档sqlite-first)
  - [1. 目标与交付物](#1-目标与交付物)
    - [1.1 目标](#11-目标)
    - [1.2 v0.1 交付物](#12-v01-交付物)
  - [2. 范围定义](#2-范围定义)
    - [2.1 v0.1 必做](#21-v01-必做)
    - [2.2 v0.1 不做](#22-v01-不做)
  - [3. 适用场景（必须支持）](#3-适用场景必须支持)
  - [4. 关键设计原则（为未来留后路）](#4-关键设计原则为未来留后路)
  - [5. 功能需求](#5-功能需求)
    - [5.1 ingest：摄取与建库](#51-ingest摄取与建库)
    - [5.2 search：全文检索](#52-search全文检索)
    - [5.3 ask：复习/问答（SQLite 版 RAG）](#53-ask复习问答sqlite-版-rag)
    - [5.4 reformat：笔记重排版](#54-reformat笔记重排版)
    - [5.5 doctor：健康检查](#55-doctor健康检查)
  - [6. 数据库设计（SQLite）](#6-数据库设计sqlite)
    - [6.1 表结构（v0.1 最小集）](#61-表结构v01-最小集)
    - [6.2 未来预留（不影响 v0.1）](#62-未来预留不影响-v01)
  - [7. CLI 规格（v0.1 必须稳定）](#7-cli-规格v01-必须稳定)
  - [8. 验收标准（12月底 v0.1）](#8-验收标准12月底-v01)
  - [9. Python + C++ 混合的技术约束（预埋，不拖慢 v0.1）](#9-python--c-混合的技术约束预埋不拖慢-v01)
  
# AI 文档整理与知识库 Agent v0.1 需求文档（SQLite First）
  
## 1. 目标与交付物
  
### 1.1 目标
  
在本地（单用户）提供一个 CLI Agent，用于：
  
1. **重排版笔记**：将松散笔记整理成统一结构的 Markdown（模板化输出）。
2. **构建知识库**：将项目文档与笔记导入知识库，支持**增量更新**。
3. **复习与检索**：在 review/提问时可以快速检索相关内容，并能输出**可定位的引用**。
4. **可演进**：v0.1 仅依赖 SQLite（含全文索引），未来可无缝接入向量库与 C++ 加速模块。
  
### 1.2 v0.1 交付物
  
* 可运行 CLI：`agent ingest/search/ask/reformat/doctor`
* 本地数据库：`kb.sqlite`（元数据 + FTS5 全文索引）
* 统一模板：SOP / Debug / Note（三类至少一种必须完成）
* 日志与健康检查：可定位问题、可回归验证（最小 eval）
  
---
  
## 2. 范围定义
  
### 2.1 v0.1 必做
  
* 文档扫描与增量更新（mtime + hash）
* Markdown/txt 摄取、标准化、切块（chunk）
* SQLite 元数据表 + FTS5 全文索引
* 检索：关键词/全文检索（FTS）
* 问答：基于检索结果拼接上下文后生成“总结/步骤”（LLM 可选，先留接口）
* 重排版：把单份笔记整理成模板化文档，默认不覆盖原文
* 引用输出：回答必须包含引用（path + heading + chunk_id/行范围）
  
### 2.2 v0.1 不做
  
* PDF/Word 解析（v0.2+）
* 向量库（embedding/ANN）作为必选依赖（v0.2+ 可插拔）
* UI/VSCode 插件（v0.2+）
* 自动执行有副作用的操作（删改文件/跑脚本/交易下单等，v0.3+）
  
---
  
## 3. 适用场景（必须支持）
  
* US1：我有一份凌乱的笔记，希望一条命令整理成 SOP/Debug 模板。
* US2：我把 `notes/`、`docs/` 导入后，输入关键词能快速找到对应段落与引用位置。
* US3：我复盘某主题时，想让 agent 输出“相关片段 + 摘要 + 引用”，方便我回去看原文。
* US4：我更新了文件后再次 ingest，应只更新变化文件，不全量重建。
  
---
  
## 4. 关键设计原则（为未来留后路）
  
1. **SQLite 是事实账本**：文件/块/版本/引用定位都在 SQLite；未来向量库只是“召回加速器”。
2. **接口稳定**：retriever/formatter/answerer 都通过接口抽象，后续可替换实现（Python↔C++/向量库）。
3. **版本化**：chunk 规则版本号写入数据库，保证可回归、可解释。
4. **默认只读**：v0.1 不做任何可能破坏数据的自动动作（未来工具执行必须 dry-run + 审计）。
  
---
  
## 5. 功能需求
  
### 5.1 ingest：摄取与建库
  
**输入**
  
* 目录列表（默认：`notes/ docs/`）
* 文件类型白名单（默认：`.md .txt`）
* `--rebuild`（可选：全量重建）
  
**处理**
  
1. 扫描文件：记录 path、mtime、size
2. 内容读取：统一编码、统一换行
3. 解析：Markdown 识别标题/列表/代码块（最小可先做规则解析）
4. 切块（chunking）：
  
   * 按标题层级切，列表/代码块尽量不切断
   * chunk 保留：heading path（如 `H1 > H2 > H3`）
5. 增量更新：
  
   * 若 `sha256` 不变则跳过
   * 若变化：删除旧 chunks → 插入新 chunks → 更新 FTS
6. 写入数据库：files/chunks/fts/index_meta
  
**输出**
  
* 新增/更新/跳过文件数
* chunk 总数、平均长度
* 失败文件列表（含原因）
  
---
  
### 5.2 search：全文检索
  
**输入**
  
* `query`（关键词/短句）
* `--topk N`（默认 10）
* 过滤：`--path-prefix` `--type`（可选）
  
**输出**
  
* 命中列表（按相关度排序）：
  
  * path、heading、chunk_id
  * snippet（命中片段预览）
  * 可定位信息（start/end 或行号占位）
  
---
  
### 5.3 ask：复习/问答（SQLite 版 RAG）
  
> v0.1 可以先做“检索 + 结构化摘要”，LLM 可选；但接口必须预留。
  
**输入**
  
* `query`
* `--mode summary|steps|compare`（默认 summary）
* `--topk N`（默认 8）
* `--show-citations`（默认开启）
  
**处理**
  
1. 调用检索（FTS）拿 topK chunks
2. 缝合（stitching）：
  
   * 同一文件相邻 chunk 可补 1 段上下文（减少断片）
3. 生成输出：
  
   * 若无 LLM：输出“要点式摘要 + 原文引用列表”
   * 若接 LLM：输入 context，要求返回结构化答案 + 引用编号
  
**输出**
  
* 答案正文（结构化）
* 引用列表（按编号对应 chunk）
  
---
  
### 5.4 reformat：笔记重排版
  
**输入**
  
* file 或 stdin
* `--template sop|debug|note`（默认 sop）
* `--out <path>`（默认 `out/`，不覆盖）
* `--in-place`（可选但默认禁用/需确认）
  
**行为**
  
* 将原始笔记整理成模板结构（保留原信息，不“胡编”）
* 文末附“原始记录”可选（默认开启，防止丢信息）
  
---
  
### 5.5 doctor：健康检查
  
* 数据库是否可读、FTS 是否可用
* 文件与 chunk 数统计
* chunk 过短/过长比例
* 增量状态（最近一次 ingest 的 run 信息）
* （预留）向量索引状态字段（即使 v0.1 不启用）
  
---
  
## 6. 数据库设计（SQLite）
  
### 6.1 表结构（v0.1 最小集）
  
* `files`
  
  * `id INTEGER PK`
  * `path TEXT UNIQUE`
  * `mtime INTEGER`
  * `sha256 TEXT`
  * `size INTEGER`
  * `type TEXT`（md/txt）
  * `created_at, updated_at`
  
* `chunks`
  
  * `id INTEGER PK`
  * `file_id INTEGER FK`
  * `chunk_index INTEGER`（在文件内顺序）
  * `heading TEXT`（如 `H1 > H2`）
  * `start_offset INTEGER`（或 start_line）
  * `end_offset INTEGER`
  * `text TEXT`
  * `text_hash TEXT`
  * `chunk_policy_version TEXT`
  
* `chunks_fts`（FTS5 虚表）
  
  * `text`
  * `path`
  * `heading`
  
* `runs`
  
  * `id INTEGER PK`
  * `started_at, finished_at`
  * `chunk_policy_version`
  * `notes TEXT`（统计信息/失败信息）
  
### 6.2 未来预留（不影响 v0.1）
  
* `embeddings`（可选）
  
  * `chunk_id`
  * `embed_model`
  * `vector_ref`（指向本地向量索引/外部库 key）
  
---
  
## 7. CLI 规格（v0.1 必须稳定）
  
* `agent ingest <dir...> [--rebuild]`
* `agent search "<query>" [--topk 10] [--path-prefix xxx]`
* `agent ask "<query>" [--mode summary|steps|compare] [--topk 8] [--export out.md]`
* `agent reformat <file> [--template sop|debug|note] [--out out/]`
* `agent doctor`
  
---
  
## 8. 验收标准（12月底 v0.1）
  
1. ingest 能对 `notes/ docs/` 建库成功，第二次运行能正确增量更新
2. search 能稳定返回相关段落，且引用信息可回到原文件定位
3. ask 在 20 条你真实问题里，至少 70% “能省时间”
4. reformat 对任意一份凌乱笔记能生成模板化文档，且不丢关键信息
5. doctor 能报告库状态与基本统计，便于排查

---
  
## 9. Python + C++ 混合的技术约束（预埋，不拖慢 v0.1）
  
* v0.1 全流程 Python 实现，保证交付速度
* 预留 `_fast` 模块入口（pybind11），未来可加速：
  
  * hash/去重、topK 相似度、批量文本预处理
* 上层接口不变（替换 backend 不改 CLI/DB schema）
  